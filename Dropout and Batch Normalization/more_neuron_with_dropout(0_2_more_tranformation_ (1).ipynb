{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5kN8TD2_xE7"
      },
      "source": [
        "# more neuron_with dropout(0.2_more_tranformation_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqUA-DcmraHv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "import seaborn as sns\n",
        "import time\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juW6mTx4radJ"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs = 50\n",
        "batch_size = 10\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPuFaq38rbrE",
        "outputId": "d170a1f7-5513-4c7b-cd60-37fc8a9e7705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:02<00:00, 84400939.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                              download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "# Splitting the training set into train and validation sets\n",
        "train_size = int(0.8 * len(train_dataset)) # Using 80% for training\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2bJT9lvrdFJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, dropout_prob=0.2):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)\n",
        "        self.bn4 = nn.BatchNorm1d(1024)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.bn5 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.fc3 = nn.Linear(512, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = self.dropout(x)  # Applying dropout after activation function\n",
        "\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.dropout(x)  # Applying dropout after activation function\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Ensure that the device variable is defined before this line\n",
        "model = ConvNet().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPQd1ZSnW9GB"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.best_model = None  # Store the best model state\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.best_model = model.state_dict()\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.best_model = model.state_dict()  # Update the best model state\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7DByzkwrfzX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F4Va_t1bruOj",
        "outputId": "795bc072-7486-4822-d1a3-b9a24acb91e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Train Loss: 3.8090260744690894, Train Accuracy: 12.1875%, Val Loss: 3.1676635081768034, Val Accuracy: 21.86%\n",
            "Epoch [2/50], Train Loss: 3.15661553516984, Train Accuracy: 22.7725%, Val Loss: 2.7534220951795576, Val Accuracy: 29.98%\n",
            "Epoch [3/50], Train Loss: 2.8443834311664102, Train Accuracy: 28.765%, Val Loss: 2.548566437125206, Val Accuracy: 34.06%\n",
            "Epoch [4/50], Train Loss: 2.6614900622963904, Train Accuracy: 32.5275%, Val Loss: 2.4382444672584533, Val Accuracy: 36.72%\n",
            "Epoch [5/50], Train Loss: 2.523921183079481, Train Accuracy: 35.4175%, Val Loss: 2.287099301695824, Val Accuracy: 40.59%\n",
            "Epoch [6/50], Train Loss: 2.4011321821212768, Train Accuracy: 37.8525%, Val Loss: 2.2010403019785882, Val Accuracy: 42.66%\n"
          ]
        }
      ],
      "source": [
        "# Initialization for training and validation\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Training loop\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    train_losses.append(running_loss/len(train_loader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_losses.append(val_loss/len(val_loader))\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader)}, Train Accuracy: {train_accuracy}%, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}%')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss/len(val_loader), model) # use average validation loss\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Save the best model at the end of the training\n",
        "try:\n",
        "    if early_stopping.best_model:\n",
        "        torch.save(early_stopping.best_model, '/content/drive/My Drive/checkpoint.pt')\n",
        "        print(\"Best model saved to '/content/drive/My Drive/checkpoint.pt'\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the model: {e}\")\n",
        "\n",
        "\n",
        "# Loading the best model weights\n",
        "print(\"Loading best model weights...\")\n",
        "try:\n",
        "    model.load_state_dict(early_stopping.best_model)\n",
        "    print(\"Best model weights loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the model weights: {e}\")\n",
        "\n",
        "print(f\"Total training time: {end_time - start_time}s\")\n",
        "print(f\"Average time per epoch: {(end_time - start_time) / (epoch+1)}s\")  # Use (epoch+1) since epoch starts from 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlXz9ZZx9tVq"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plotting Training and Validation Losses\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')  # Changed from test_losses\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting Training and Validation Accuracies\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')  # Changed from test_accuracies\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExWaREk6dpCx"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    # Compute confusion matrix\n",
        "    matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot using Seaborn\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    sns.set(font_scale=1.2)\n",
        "    sns.heatmap(matrix, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "    # Only annotate cells with more than a threshold (e.g., 10) misclassifications to avoid clutter\n",
        "    threshold = 10\n",
        "    for i, j in zip(*np.where(matrix > threshold)):\n",
        "        plt.text(j+0.5, i+0.5, matrix[i, j],\n",
        "                 fontsize=12,\n",
        "                 ha='center',\n",
        "                 va='center',\n",
        "                 color='red')\n",
        "\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.title('Confusion Matrix with Selective Annotations')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1BCgn4ga5Ux"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeRsgzrjsum9"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision, recall, f_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')  # Added f_score\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F-Score: {f_score:.2f}\")  # Printing F-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH9xZu2QsyeD"
      },
      "outputs": [],
      "source": [
        "class_names = ['beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "'aquarium' ,'fish', 'ray', 'shark', 'trout',\n",
        "'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "'baby', 'boy', 'girl', 'man', 'woman',\n",
        "'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',\n",
        "'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
        "\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L691eF-99nNK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfzAhgYo9nNK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}